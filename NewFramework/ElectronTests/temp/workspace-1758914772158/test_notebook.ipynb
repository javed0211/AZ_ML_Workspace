{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Project Notebook\n",
    "\n",
    "This notebook demonstrates Azure ML workflows and data science operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ Azure ML Project Started!\")\n",
    "print(f\"üìÖ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"üìä Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for Azure ML demonstration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'age': np.random.randint(18, 80, n_samples),\n",
    "    'income': np.random.normal(50000, 20000, n_samples),\n",
    "    'experience': np.random.randint(0, 40, n_samples),\n",
    "    'education_score': np.random.normal(75, 15, n_samples),\n",
    "    'satisfaction': np.random.choice([0, 1], n_samples, p=[0.3, 0.7])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['income'] = np.clip(df['income'], 20000, 150000)  # Realistic income range\n",
    "df['education_score'] = np.clip(df['education_score'], 0, 100)  # Score 0-100\n",
    "\n",
    "print(\"üìä Dataset Created:\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "print(\"\\nüîç First 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview and statistics\n",
    "print(\"üìà Dataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nüéØ Target Variable Distribution:\")\n",
    "satisfaction_counts = df['satisfaction'].value_counts()\n",
    "print(f\"   Satisfied (1): {satisfaction_counts[1]} ({satisfaction_counts[1]/len(df)*100:.1f}%)\")\n",
    "print(f\"   Not Satisfied (0): {satisfaction_counts[0]} ({satisfaction_counts[0]/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Age distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.hist(df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Income distribution\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.hist(df['income'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "plt.title('Income Distribution')\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Experience vs Income\n",
    "plt.subplot(2, 3, 3)\n",
    "scatter = plt.scatter(df['experience'], df['income'], c=df['satisfaction'], \n",
    "                     cmap='viridis', alpha=0.6)\n",
    "plt.title('Experience vs Income')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Income ($)')\n",
    "plt.colorbar(scatter, label='Satisfaction')\n",
    "\n",
    "# Education score distribution\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.hist(df['education_score'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "plt.title('Education Score Distribution')\n",
    "plt.xlabel('Education Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Satisfaction by age groups\n",
    "plt.subplot(2, 3, 5)\n",
    "age_groups = pd.cut(df['age'], bins=[0, 30, 45, 60, 100], labels=['18-30', '31-45', '46-60', '60+'])\n",
    "satisfaction_by_age = df.groupby(age_groups)['satisfaction'].mean()\n",
    "satisfaction_by_age.plot(kind='bar', color='coral')\n",
    "plt.title('Satisfaction Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Satisfaction Rate')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.subplot(2, 3, 6)\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualizations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare features and target\n",
    "X = df[['age', 'income', 'experience', 'education_score']]\n",
    "y = df['satisfaction']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"üîÑ Data Split:\")\n",
    "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Scale features for logistic regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Feature scaling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"ü§ñ Training Models:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for logistic regression, original for tree-based models\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ Test Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   üìä CV Score: {cv_mean:.3f} (¬±{cv_std:.3f})\")\n",
    "\n",
    "print(\"\\nüèÜ Model Training Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison and detailed results\n",
    "print(\"üìä Model Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test Accuracy': [results[name]['accuracy'] for name in results.keys()],\n",
    "    'CV Mean': [results[name]['cv_mean'] for name in results.keys()],\n",
    "    'CV Std': [results[name]['cv_std'] for name in results.keys()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Test Accuracy', ascending=False)\n",
    "display(comparison_df)\n",
    "\n",
    "# Best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\nü•á Best Model: {best_model_name}\")\n",
    "print(f\"   Accuracy: {results[best_model_name]['accuracy']:.3f}\")\n",
    "\n",
    "# Detailed classification report for best model\n",
    "print(f\"\\nüìã Detailed Classification Report ({best_model_name}):\")\n",
    "print(classification_report(y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (for tree-based models)\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"üéØ Feature Importance Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    display(feature_importance)\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    # For logistic regression, show coefficients\n",
    "    coefficients = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'coefficient': best_model.coef_[0]\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"üéØ Model Coefficients (Logistic Regression):\")\n",
    "    print(\"=\" * 45)\n",
    "    display(coefficients)\n",
    "    \n",
    "    # Visualize coefficients\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=coefficients, x='coefficient', y='feature', palette='coolwarm')\n",
    "    plt.title('Model Coefficients - Logistic Regression')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Features')\n",
    "    plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Azure ML Integration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ML Integration Template\n",
    "print(\"‚òÅÔ∏è Azure ML Integration Template\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "azure_ml_template = \"\"\"\n",
    "# Azure ML SDK Integration Example\n",
    "# Uncomment and configure the following code to use with Azure ML\n",
    "\n",
    "# from azureml.core import Workspace, Experiment, Environment\n",
    "# from azureml.core.model import Model\n",
    "# from azureml.core.run import Run\n",
    "# import joblib\n",
    "\n",
    "# # Connect to Azure ML Workspace\n",
    "# ws = Workspace.from_config()  # or Workspace.get(name='your-workspace', \n",
    "#                               #                   subscription_id='your-sub-id',\n",
    "#                               #                   resource_group='your-rg')\n",
    "\n",
    "# # Create or get experiment\n",
    "# experiment = Experiment(workspace=ws, name='satisfaction-prediction')\n",
    "\n",
    "# # Start a run\n",
    "# run = experiment.start_logging()\n",
    "\n",
    "# # Log metrics\n",
    "# run.log('accuracy', best_accuracy)\n",
    "# run.log('model_type', best_model_name)\n",
    "\n",
    "# # Save and register model\n",
    "# model_filename = 'satisfaction_model.pkl'\n",
    "# joblib.dump(best_model, model_filename)\n",
    "\n",
    "# # Upload model file\n",
    "# run.upload_file(name=model_filename, path_or_stream=model_filename)\n",
    "\n",
    "# # Register model\n",
    "# model = run.register_model(model_name='satisfaction-predictor',\n",
    "#                           model_path=model_filename,\n",
    "#                           description='Employee satisfaction prediction model')\n",
    "\n",
    "# # Complete the run\n",
    "# run.complete()\n",
    "\n",
    "# print(f\"Model registered: {model.name} version {model.version}\")\n",
    "\"\"\"\n",
    "\n",
    "print(azure_ml_template)\n",
    "\n",
    "# Configuration template\n",
    "config_template = {\n",
    "    \"subscription_id\": \"your-azure-subscription-id\",\n",
    "    \"resource_group\": \"your-resource-group-name\",\n",
    "    \"workspace_name\": \"your-azureml-workspace-name\",\n",
    "    \"experiment_name\": \"satisfaction-prediction\",\n",
    "    \"model_name\": \"satisfaction-predictor\"\n",
    "}\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Configuration Template:\")\n",
    "for key, value in config_template.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ Azure ML template ready for customization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project summary\n",
    "print(\"üéâ PROJECT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Dataset: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "print(f\"ü§ñ Models Trained: {len(models)}\")\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üéØ Best Accuracy: {results[best_model_name]['accuracy']:.3f}\")\n",
    "print(f\"‚è∞ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"   1. Configure Azure ML workspace credentials\")\n",
    "print(\"   2. Uncomment and run Azure ML integration code\")\n",
    "print(\"   3. Deploy model to Azure ML endpoint\")\n",
    "print(\"   4. Set up monitoring and retraining pipeline\")\n",
    "print(\"   5. Create web service for predictions\")\n",
    "\n",
    "print(\"\\n‚ú® Happy Machine Learning with Azure ML! ‚ú®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}